{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "# np, pd, plt,itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# sklearn\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size = \"4\"> 1. Create data generating process function </font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent predictor data generating process\n",
    "def latent(N=200,P=20,K=5):\n",
    "    np.random.seed(1) # fix the simulation results\n",
    "    #N = num. observations\n",
    "    #K = num. predictors\n",
    "    #P = num. observed predictors\n",
    "\n",
    "    Z = np.random.randn(N,K)\n",
    "    gamma = np.random.rand(K,P)\n",
    "    X = np.dot(Z,gamma)+np.random.randn(N,P)\n",
    "    beta = np.ones((K,1))\n",
    "    y = np.dot(Z,beta) + np.random.randn(N,1)\n",
    "    data = pd.DataFrame(np.concatenate((y,X),axis=1))\n",
    "\n",
    "    return data,N,P,Z,X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse signal data generating process\n",
    "def sparse(N=200,P=20,K=5):\n",
    "    np.random.seed(1) # fix the simulation results\n",
    "    #N = num. observations\n",
    "    #K = num. predictors\n",
    "    #P = num. observed predictors\n",
    "\n",
    "    X = np.random.randn(N,P)\n",
    "    Z = X[:,:K]\n",
    "    beta = np.ones((K,1))\n",
    "    y = np.dot(Z,beta) + np.random.randn(N,1)\n",
    "    data = pd.DataFrame(np.concatenate((y,X),axis=1))\n",
    "\n",
    "    return data,N,P,Z,X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size = \"4\">2. Generate and preprocess data</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate \"Latent\" data\n",
    "data,N,P,Z,X,y = latent(N=1000,P=20,K=5)\n",
    "\n",
    "# Generate \"Sparse\" data\n",
    "#data,N,P,Z,X,y = sparse(N=1000,P=20,K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and test\n",
    "X_train = data.iloc[:int(N/2),1:]\n",
    "y_train = data.iloc[:int(N/2),0]\n",
    "X_test = data.iloc[int(N/2):,1:]\n",
    "y_test = data.iloc[int(N/2):,0]\n",
    "\n",
    "# Standardize X\n",
    "X_train = X_train.sub(np.mean(X_train,axis=0)).div(np.std(X_train,axis=0))\n",
    "X_test = X_test.sub(np.mean(X_test,axis=0)).div(np.std(X_test,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of columns\n",
    "ncol = len(X_train.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size = \"4\">3. Apply alogrithms</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Shrinkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeCV MSE:  1.18268269518466\n"
     ]
    }
   ],
   "source": [
    "# Ridge CV\n",
    "rcv = RidgeCV(cv=5)\n",
    "rcv = rcv.fit(X_train,y_train)\n",
    "cv_ridge_mse = mean_squared_error(rcv.predict(X_test),y_test)\n",
    "print('RidgeCV MSE: ',cv_ridge_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV MSE:  1.1825003367163036\n"
     ]
    }
   ],
   "source": [
    "# Lasso CV\n",
    "lcv = LassoCV(cv=5)\n",
    "lcv = lcv.fit(X_train,y_train)\n",
    "cv_lasso_mse = mean_squared_error(lcv.predict(X_test),y_test)\n",
    "print('LassoCV MSE: ',cv_lasso_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA CV MSE:  1.188276665535775\n"
     ]
    }
   ],
   "source": [
    "# PCA\n",
    "# Fit and transform PCA \n",
    "pca = PCA(n_components = None)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Define Kfold\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "\n",
    "# Initalize regressor and MSE\n",
    "regr = LinearRegression()\n",
    "mse = []\n",
    "\n",
    "# Loop for number of variables\n",
    "for i in range(1,ncol+1):\n",
    "    score = -1*cross_val_score(regr,X_train_pca[:,:i+1],y_train,cv=kf,scoring='neg_mean_squared_error').mean()\n",
    "    mse.append(score)\n",
    "\n",
    "# Number of companents with min MSE\n",
    "best_nvar = np.argmin(mse)+1\n",
    "\n",
    "# Obtain OOS MSE\n",
    "regr = regr.fit(X_train_pca[:,:best_nvar+1],y_train)\n",
    "cv_pca_mse = mean_squared_error(y_test,regr.predict(X_test_pca[:,:best_nvar+1]))\n",
    "print('PCA CV MSE: ',cv_pca_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLS CV MSE:  1.1830988488733103\n"
     ]
    }
   ],
   "source": [
    "# PLS\n",
    "# Define Kfold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# Loop for number of variables\n",
    "for i in range(1, ncol+1):\n",
    "    pls = PLSRegression(n_components=i)\n",
    "    score = cross_val_score(pls,X_train,y_train,cv=kf,scoring='neg_mean_squared_error').mean()\n",
    "    mse.append(-score)\n",
    "\n",
    "# Number of companents with min MSE\n",
    "best_nvar = np.argmin(mse)+1\n",
    "\n",
    "# Obtain OOS MSE\n",
    "pls = PLSRegression(n_components=best_nvar)\n",
    "pls = pls.fit(X_train,y_train)\n",
    "cv_pls_mse = mean_squared_error(y_test,pls.predict(X_test))\n",
    "print('PLS CV MSE: ',cv_pls_mse)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOS_MSE function\n",
    "def oos_mse(X_train,X_test,y_train,y_test):\n",
    "    regr = LinearRegression()\n",
    "    regr = regr.fit(X_train,y_train)\n",
    "    mse = mean_squared_error(y_test,regr.predict(X_test))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward stepwise function\n",
    "def forward_stepwise(X_train,X_test,y_train,y_test,nvmax=5,ncv=5,standardize=True):\n",
    "    # Column names\n",
    "    col_name = X_train.columns.values    \n",
    "    \n",
    "    # Standardize X\n",
    "    if standardize:\n",
    "        X_train = X_train.sub(np.mean(X_train,axis=0)).div(np.std(X_train,axis=0))\n",
    "        X_test = X_test.sub(np.mean(X_test,axis=0)).div(np.std(X_test,axis=0))\n",
    "\n",
    "    # Number of columns\n",
    "    ncol = len(X_train.iloc[0])\n",
    "    # Number of rows\n",
    "    nrow = len(y_train)\n",
    "\n",
    "    # Define Kfold\n",
    "    kf = KFold(n_splits=ncv,shuffle=True,random_state=1)\n",
    "    \n",
    "    # Initalize attribute list and MSE\n",
    "    attr = []\n",
    "    mse = []  \n",
    "    \n",
    "    # Create a variable list for variable addition during the loop \n",
    "    remaining = col_name    \n",
    "    \n",
    "    # Forward stepwise loop\n",
    "    regr = LinearRegression()\n",
    "    for i in range(nvmax):\n",
    "        # Intialize temp MSE list for holding the MSE of every trials\n",
    "        temp_mse = [] \n",
    "        for var in remaining:\n",
    "            attr_try = attr + [var]        \n",
    "            score = cross_val_score(regr,X_train[attr_try],y_train,cv=kf,scoring='neg_mean_squared_error').mean()\n",
    "            temp_mse.append(-score)\n",
    "            \n",
    "        best_var_id = np.argmin(temp_mse) # Locate index with lowest MSE\n",
    "        attr.append(remaining[best_var_id]) # Append the best variable to attribute list\n",
    "        remaining = list(set(remaining)-set(attr)) # Update the remaining attributes list \n",
    "        mse.append(np.min(temp_mse)) # Update MSE after adding one more variable\n",
    "    \n",
    "    best_var = attr[:np.argmin(mse)+1]\n",
    "    cv_fw_mse = oos_mse(X_train[best_var],X_test[best_var],y_train,y_test)\n",
    "    return cv_fw_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Selection CV MSE:  1.311129850484197\n"
     ]
    }
   ],
   "source": [
    "# Forward stepwise\n",
    "cv_fw_mse = forward_stepwise(X_train,X_test,y_train,y_test,nvmax=7,ncv=5)\n",
    "print('Forward Selection CV MSE: ',cv_fw_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best subset function\n",
    "def best_subset(X_train,X_test,y_train,y_test,nvmax=5,ncv=5,standardize=True):\n",
    "    # Column names\n",
    "    col_name = X_train.columns.values    \n",
    "    \n",
    "    # Standardize X\n",
    "    if standardize:\n",
    "        X_train = X_train.sub(np.mean(X_train,axis=0)).div(np.std(X_train,axis=0))\n",
    "        X_test = X_test.sub(np.mean(X_test,axis=0)).div(np.std(X_test,axis=0))\n",
    "\n",
    "    # Number of columns\n",
    "    ncol = len(X_train.iloc[0])\n",
    "    # Number of rows\n",
    "    nrow = len(y_train)\n",
    "\n",
    "    # Define Kfold\n",
    "    kf = KFold(n_splits=ncv,shuffle=True,random_state=1)\n",
    "    \n",
    "    # Initalize attribute list and MSE\n",
    "    attr = []\n",
    "    mse = []  \n",
    "    \n",
    "    # Create a variable list for variable addition during the loop \n",
    "    remaining = col_name    \n",
    "    \n",
    "    # Best subset loop\n",
    "    regr=LinearRegression()\n",
    "    for i in range(nvmax):\n",
    "        for combo in itertools.combinations(col_name, i+1):           \n",
    "            attr.append(list(combo)) #Create a attribute list for all possible combinations of attributes\n",
    "            score = cross_val_score(regr,X_train[list(combo)],y_train,cv=kf,scoring='neg_mean_squared_error').mean()\n",
    "            mse.append(-score)\n",
    "    \n",
    "    best_var = attr[np.argmin(mse)]\n",
    "    cv_bs_mse = oos_mse(X_train[best_var],X_test[best_var],y_train,y_test)\n",
    "    return cv_bs_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST SUBSET CV MSE:  1.3193944465999117\n"
     ]
    }
   ],
   "source": [
    "# Best subset\n",
    "cv_bs_mse=best_subset(X_train,X_test,y_train,y_test,nvmax=7,ncv=5)\n",
    "print('BEST SUBSET CV MSE: ',cv_bs_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 OLS without dimesnion reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS MSE:  1.1830996231146003\n"
     ]
    }
   ],
   "source": [
    "# OLS\n",
    "ols_mse = oos_mse(X_train,X_test,y_train,y_test)\n",
    "print('OLS MSE: ',ols_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "3.5 Oracle (True model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORACLE MSE:  0.9789935606967682\n"
     ]
    }
   ],
   "source": [
    "# Oracle\n",
    "oracle_data = pd.DataFrame(np.hstack((y,Z)))\n",
    "\n",
    "# Split training and test\n",
    "X_train = oracle_data.iloc[:int(N/2),1:]\n",
    "y_train = oracle_data.iloc[:int(N/2),0]\n",
    "X_test = oracle_data.iloc[int(N/2):,1:]\n",
    "y_test = oracle_data.iloc[int(N/2):,0]\n",
    "\n",
    "# Standardize X\n",
    "X_train = X_train.sub(np.mean(X_train,axis=0)).div(np.std(X_train,axis=0))\n",
    "X_test = X_test.sub(np.mean(X_test,axis=0)).div(np.std(X_test,axis=0))\n",
    "\n",
    "# Obtain OOS MSE\n",
    "regr=LinearRegression()\n",
    "regr=regr.fit(X_train,y_train)\n",
    "oracle_mse=mean_squared_error(y_test,regr.predict(X_test))\n",
    "print('ORACLE MSE: ',oracle_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b><font size = \"4\">Summary (MSE comparison among different models)<font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Oracle              0.978994\n",
      "Lasso               1.182500\n",
      "Ridge               1.182683\n",
      "PLS                 1.183099\n",
      "OLS                 1.183100\n",
      "PCA                 1.188277\n",
      "Forward stepwise    1.311130\n",
      "Best subset         1.319394\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x223704f7320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary for model comparison\n",
    "mse_summary = pd.Series({'Ridge':cv_ridge_mse,\n",
    "                         'Lasso':cv_lasso_mse,\n",
    "                         'PCA':cv_pca_mse,\n",
    "                         'PLS':cv_pls_mse,\n",
    "                         'Best subset':cv_bs_mse,\n",
    "                         'Forward stepwise':cv_fw_mse,\n",
    "                         'OLS': ols_mse,'Oracle':oracle_mse}).sort_values()\n",
    "\n",
    "# Print summary\n",
    "print('Summary:')\n",
    "print(mse_summary)\n",
    "\n",
    "# Plot summary\n",
    "mse_summary[::-1].plot(kind='barh')\n",
    "plt.xlabel('Out-of-sample mean square error')\n",
    "plt.title('Model Comparison')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
